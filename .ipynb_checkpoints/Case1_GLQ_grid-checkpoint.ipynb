{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a486c8cb-1429-47aa-bcc0-c4b979ce439a",
   "metadata": {},
   "source": [
    "# Stokes coefficients estimation\n",
    "In this set of notebooks, we show simulations of retrival of a set of real spherical harmonics gravity coefficients from a set of gravitational measurements (either potential or acceleration). This is a simplified example of what is performed in an orbit determination (OD) campaign, where the Stokes coefficients are estimated, along with other parameters, from a set of radio-tracking measurements of an orbiting spacecraft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ba0eb-2f29-4cee-b06b-b87c81a35f63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Gravity and spherical harmonics\n",
    "The gravitational potential U at a point $(r, \\theta, \\phi)$ - radius, colatitude, and longitude - is modelled as a series of spherical harmonics truncated at degree `n_max`:\n",
    "$$U(r,\\theta,\\phi) = \\frac{\\mu}{r}\\sum_{n=0}^{n_{\\max}} \\sum_{m=0}^{m=l}  {\\left(\\frac{R_0}{r}\\right)}^n P_{lm}(\\cos{\\theta})\\left[C_{lm}cos{m\\lambda}+S_{lm}\\sin{m\\lambda}\\right]$$\n",
    "where $\\mu$ (in the code, `gm`) is the product of the mass of the central body and the universal gravitational constant, and $R_0$ a reference radius. The spherical harmonics functions and corresponding Stokes coeffcients ($C_{lm}, S_{lm}$), are real-valued, $4\\pi$-normalized, and exclude the Condon-Shortley phase factor of $(-1)^m$. More details can be found in the relevant SHTOOLS [documentation page](https://shtools.github.io/SHTOOLS/real-spherical-harmonics.html). They correspond indeed to the default convention for real spherical harmonics in SHTOOLS.\n",
    "We follow the geodesy and geophysics sign conventions, with the potential positive and $\\mathbf{g} = +\\nabla U $ .  \n",
    "The gravitational accelerations is then given by the gradient of the potential, that is:\n",
    "$$\\mathbf{g} = \\nabla U = \\frac{\\partial U}{\\partial r} \\mathbf{u_r} + \\frac{1}{r}\\frac{\\partial U}{\\partial \\theta} \\mathbf{u_\\theta}+ \\frac{1}{r\\sin{\\theta}} \\frac{\\partial U}{\\partial \\lambda} \\mathbf{u_\\lambda}$$\n",
    "Therefore, the three components in the directions of $\\mathbf{u_r}, \\mathbf{u_\\theta}$, and $\\mathbf{u_\\phi}$ are:\n",
    "$$g_r = -\\frac{\\mu}{r^2}\\sum_{n=0}^{n_{\\max}} \\sum_{m=0}^{m=l} (n+1) {\\left(\\frac{R_0}{r}\\right)}^n P_{lm}(\\cos{\\theta})\\left[C_{lm}\\cos{m\\lambda}+S_{lm}\\sin{m\\lambda}\\right]$$\n",
    "$$g_\\theta = \\frac{\\mu}{r^2}\\sum_{n=0}^{n_{\\max}} \\sum_{m=0}^{m=l} {\\left(\\frac{R_0}{r}\\right)}^n \\frac{\\partial P_{lm}(\\cos{\\theta})}\n",
    "{\\partial \\theta}\\left[C_{lm}\\cos{m\\lambda}+S_{lm}\\sin{m\\lambda}\\right]$$\n",
    "$$g_\\lambda = \\frac{\\mu}{r^2}\\sum_{n=0}^{n_{\\max}} \\sum_{m=0}^{m=l} {\\left(\\frac{R_0}{r}\\right)}^n m \\frac{P_{lm}(\\cos{\\theta})}{\\sin{\\theta}}\\left[-C_{lm}\\sin{m\\lambda}+S_{lm}\\cos{m\\lambda}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231590a-f573-4a6e-bc59-f38356686f8b",
   "metadata": {},
   "source": [
    "## Problem formulation\n",
    "We strive to reconstruct a the gravitational field of a body, in the form of its Stokes coefficients $C_{lm}, S_{lm}$, starting from measurements of $U$ or $\\nabla U$ obtained over discrete points in $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9dcc47-cb9c-4d8c-8e6a-bd1ebeba6cf0",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "There are some critical differences between what is shown here and what is actually done in orbit determination.\n",
    "- In OD, **gravity measurements are not directly available**, since the tracked object is in free-fall. Where present, an accelerometer can provide measurements of all non-gravitational effects, which can then be removed from the total acceleration predicted for the spacecraft. In general, however, an initial dynamical model is constructed, which predicts the effect of both gravitational and non-gravitational forces acting on the spacecraft. Starting from an *a priori* initial state for the spacecraft, its trajectory is numerically propagated according to this dynamical model, and a measurement model is used to generate predicted values for the observables at the time-stamps of the available measurements. Then a filter is used to minimize the discrepancy between computed and raw measurements, by estimating (through iterations) corrections for the parameters of the dynamical model and for the initial state of the propagated trajectory.\n",
    "- In OD, the available measurements are typically **1-dimensional**. Mainly, Doppler and range measurements are used, which provide, respectively, the relative velocity and the distance between a spacecraft and a ground station on Earth, along the line-of-sight. Here, instead, we assume that gravity measurements are available directly, at specific points along the trajectory. This presupposes a preliminar orbit reconstruction step, where the gravity information is extracted from the radio-tracking data. As the accuracy of the gravity reconstruction can be assumed to scale with the coverage of the radio-tracking measurements, we still base the selection of the gravity measurements points on realistic tracking schedules for Doppler data.\n",
    "- Our OD software (MONTE) relies on an **Extended Kalman Filter** for the parameter estimation. Here, as there are no time-variable parameters, we opt for a simple batch least-squares inversion instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afd116-8953-47f4-929d-964a73403768",
   "metadata": {},
   "source": [
    "## **Case 1**: Fitting gravity acceleration points over a regular grid\n",
    "In this very ideal case, we assume that the gravity information is available on a spherical grid. The grid points are those of the Gauss-Legendre Quadrature grid in SHTOOLS, which therefore depend on the maximum degree of the spherical harmonics coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f8060-9787-4193-a583-67cfd5d8db21",
   "metadata": {},
   "source": [
    "Dependencies can be installed via pip (using the requirements.txt file). We use plotly for graphics, pyshtools for handling spherical harmonics, and spiceypy for orbital computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbe0dfc-5c94-4511-90d6-ea91daa01c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pyshtools as sh\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pk\n",
    "import json\n",
    "\n",
    "import scripts\n",
    "from scripts._units import *\n",
    "\n",
    "from IPython.display import IFrame\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6f8ab-598d-4374-b774-5677e0137f08",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf68b83-90de-40f2-a8b8-797387f50c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = \"glq_grid\" # outputs destination folder (a subfolder of out)\n",
    "out_path = os.path.join(\"out\", out_name)\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "use_potential = False # Whether to work with potential (flag to True) or with accelerations (flag to False)\n",
    "perturb_msr = False # Whether to introduce additive Gaussian noise in the syntehtic measurements\n",
    "drop_traj_points = False # Only keep locations of measurement points, to save on memory (needed when using realistic trajectories) \n",
    "compute_covariance = True # Additionally compute uncertainties for the estimated coefficients (~20% increase in inversion time)\n",
    "check_acc_msr = True # Compare acceleartion measurements with those given by pyshtools\n",
    "\n",
    "msr_dim = 1 if use_potential else 3 # dimensions of each measurerment (i.e. scalar or vector)\n",
    "partials_func = scripts.pot_cnm_partials if use_potential else scripts.acc_cnm_partials # function to use for partials computation\n",
    "val_lbl = \"U_grav (m^2/s^2)\" if use_potential else \"|a_grav| (m/s^2)\" # label for plots\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2b3c6-f70c-49a1-9eae-606789353b50",
   "metadata": {},
   "source": [
    "### Ground-truth gravity\n",
    "For this case, we select as ground-truth the gravity coefficients of Mars, as estimated by Konopliv, et al. (2016), and available on the [NASA PDS](https://pds-geosciences.wustl.edu/mro/mro-m-rss-5-sdp-v1/mrors_1xxx/data/shadr/). The coefficients and their uncertainties are provided up to degree and order 120. This solution, MRO120D, was obtained by processing radio-tracking data of 3 Martian orbiters (and 3 landers), acquired over a span of 15 years, for a total of about 5 million measurement points (when converted to a 60s count time). Replicating such an extended tracking schedule would be excessively computationally intensive. Here, we limit our estimation to below 100 thousand points. We expect, however, that given our strong simplification of the OD process (as described above), a significantly smaller amount of observations compared to real OD campaign is required to reach comparable gravity reconstruction accuracies.\n",
    "\n",
    "In this case, we deal with 2 sets of coefficients: one used to generate synthetic measurements (`_sim`) and whose values are read from MRO120D, and the other (`_est`) whose values have to be estimated. The two sets of coefficients can have a different maximum degree.\n",
    "\n",
    "For compatibility with SHTOOLS, we store the coefficients in matrices of size `(2,n_max+1,n_max+1)`. However, for computations we rely on 1D arrays. The array `cnm_idx` associates to each index of the vector a tuple of indices for the matrix, and vice-versa for the dictionary `cnm_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efa63b7-ef12-4c1d-95b8-b221be31a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SH degree cutoff (for both simulation and estimation, and in any case limited by that of the file)\n",
    "n_max_sim = 120 # macimum degree of the coefficients used to simulate the measurements\n",
    "n_max_est = 100 # maximum degree of the coefficients to be estimated\n",
    "n_max = max(n_max_sim, n_max_est)\n",
    "\n",
    "# Read SH coefficients, and cut to n_max_sim\n",
    "file_name = \"spice/data/jgmro_120d_sha.tab\"\n",
    "cnm_mat, r_0, gm = scripts.read_SHADR(file_name)\n",
    "cnm_mat_sim = cnm_mat[:, : n_max_sim + 1, : n_max_sim + 1]\n",
    "\n",
    "# Index array and dictionary to go from a matrix of Cnm to a 1D array, and vice-versa\n",
    "cnm_idx_sim, cnm_map_sim = scripts.get_cnm_idx(n_max_sim)\n",
    "cnm_idx_est, cnm_map_est = scripts.get_cnm_idx(n_max_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560458bd-7b58-41c9-8c69-7fb1affdab63",
   "metadata": {},
   "source": [
    "### Points selection\n",
    "In this simple case, there is no trajectory behind our selection of the measurement points, which are instead sampled over the SHTOOLS GLQ grid for degree `n_max_sim` and at a constant altitude of 234 km, close to the altitude of the Mars Reconnaissance Orbiter (MRO) spacecraft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023c3e34-d428-4721-b995-79f59b4975fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cartesian and spherical coordinates of the grid points\n",
    "state_mat, sph_coords = scripts.points_from_grid(n_max_sim, r=(r_0 + 234.0 * km)) \n",
    "n_msr_pts = state_mat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759b939-ac61-4a37-84e2-fbca1acf3a06",
   "metadata": {},
   "source": [
    "## Forward model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95090937-802a-498c-81e7-9ab83edc94cc",
   "metadata": {},
   "source": [
    "### Simulating measurements\n",
    "Given the measurements locations and the matrix of Stokes coefficients, the gravity measurements can be simulated following the equations above. If the simulation and estimation sets of coefficients have the same maximum degree, however, the computation of the synthetic measurements is performed in the next cell, at the same time as the computation of the partials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d0a7c9-b876-49cd-94a1-ff584b1d5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing synthetic measurements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 121/121 [00:30<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceleration error wrt SHTOOLS [5.19261646e-14 7.23254065e-16 6.86207023e-16]\n",
      "Took 41.39 s\n"
     ]
    }
   ],
   "source": [
    "sim_msr_vec = None\n",
    "if n_max_sim != n_max_est:\n",
    "    print(\"Computing synthetic measurements...\")\n",
    "    ts = time()\n",
    "\n",
    "    # Compute potential and acceleration at the selected coordinates\n",
    "    pot_sim, acc_sim = scripts.compute_pot_acc(\n",
    "        cnm_mat_sim, r_0, sph_coords\n",
    "    )\n",
    "    pot_sim *= gm\n",
    "    acc_sim *= gm\n",
    "    # Pick right observable, and convert to 1D array\n",
    "    if use_potential:\n",
    "        sim_msr_vec = pot_sim.reshape(n_msr_pts * msr_dim)\n",
    "    else:\n",
    "        sim_msr_vec = acc_sim.reshape(n_msr_pts * msr_dim)\n",
    "\n",
    "    # A little hacky, but for now this is stored as a bool to economize on memory\n",
    "    cnm_mat_est = np.empty((2, n_max_est + 1, n_max_est + 1), dtype=bool)\n",
    "\n",
    "    # Compare the obtained acceleration values with those computed by SHTOOLS\n",
    "    if check_acc_msr:\n",
    "        sh_coeffs = sh.SHGravCoeffs.from_array(cnm_mat_sim, gm, r_0)\n",
    "        acc_shtools = np.array(\n",
    "            [\n",
    "                sh_coeffs.expand(colat=acc[1] / deg, lon=acc[2] / deg, a=acc[0])\n",
    "                for acc in sph_coords\n",
    "            ]\n",
    "        )\n",
    "        print(\n",
    "            \"Acceleration error wrt SHTOOLS\",\n",
    "            np.linalg.norm(acc_sim - acc_shtools, axis=0),\n",
    "        )\n",
    "    print(\"Took {:.2f} s\".format(time() - ts))\n",
    "else:\n",
    "    # I the maximum degrees are the same, the computation is done below\n",
    "    cnm_mat_est = cnm_mat_sim.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9924ca9-2717-4a54-949d-2387aafe4ca0",
   "metadata": {},
   "source": [
    "### Computing partials\n",
    "The relation between gravity and the Stokes coefficient is linear, and can be expressed via the system:\n",
    "$$\\mathbf{z} = \\mathbf{H}\\mathbf{x} + \\mathbf{\\nu}$$\n",
    "If $\\mathbf{\\tilde{H}}$ is the matrix of the partials w/r/t the Stokes coefficients and $\\mathbf{\\tilde{z}}$ the vector of measurements with covariance $\\mathbf{W}$, then\n",
    "$$\\mathbf{H} = \\mathbf{W}^{1/2}\\tilde{\\mathbf{H}},$$ \n",
    "$$\\mathbf{z} = \\mathbf{W}^{1/2}\\tilde{\\mathbf{z}},$$\n",
    "so as to have the weighted errors $\\mathbf{\\nu}$ be independent and with unitary variance, meaning $E[\\mathbf{\\nu}] = \\mathbf{I}$. The expression of the partials of the measurements with respect to the Stokes coefficients can be easily derived from the formulas in the first cell. Here we assume that $\\mathbf{W}$ is diagonal, i.e. that the measurements are independent, each with noise of standard deviation $\\sigma_i$, stored in the vector (or scalar) `msr_noise` in the code.\n",
    "\n",
    "The least-squares solution $\\hat{\\mathbf{x}}$ of this over-determined system can be found by inverting the normal equations:\n",
    "$$\\mathbf{H}^T\\mathbf{H}\\hat{\\mathbf{x}} = \\mathbf{H}^T\\mathbf{z}$$\n",
    "where we define $\\mathbf{N}=\\mathbf{H}^T\\mathbf{H}$ (the normal matrix) and $\\mathbf{y} = \\mathbf{H}^T\\mathbf{z}$. \n",
    "#### Using normal equations  \n",
    "As suggested by Jorge, in order to limit the memory requirements, we form the normal equations directly, so that we only need to store a matrix of size `(n_params, n_params)`, instead of the partials matrix of size `(n_msr, n_params)`. It is of course not advisable to go through the normal equations when solving a least squares system, but instead perform a decomposition of the matrix $\\mathbf{H}$, because of the higher possibility for numerical errors (the condition number of $\\mathbf{N}$ is the square of that of $\\mathbf{H}$.  However, since operating on $\\mathbf{H}$ is deemed too computationally expensive for `n_max_est`>50 and the system appears to be generally well-conditioned, we opt for the normal-equations approach. A low-memory-usage alternative would be to use a sequential filter, but our Python implementation of a Kalman filter was too slow to be applied in realistic estimation scenarios.\n",
    "\n",
    "$\\mathbf{N}$ and $\\mathbf{y}$ are populated via batches of `batch_size` measurements, where `batch_size` can be increased in order to speed-up the computation, at the cost of increased memory usage. The contributions of each batch to both $\\mathbf{N}$ and $\\mathbf{y}$ can be simply added to form the final normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0eeb1a8-2a21-4c91-aca5-7cae8d1980e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Normal equations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 30/30 [02:48<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 168.94 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing Normal equations...\")\n",
    "ts = time()\n",
    "\n",
    "# measurements standard deviation. Can be a vector of size n_msr or a float. Here we take 1e-2% of the surface gravity.\n",
    "msr_noise = 1e-4 * gm / np.power(r_0, 1 if use_potential else 2)\n",
    "# in the scripts, the partials are computed up to a factor of gm\n",
    "partials_scale = gm\n",
    "\n",
    "# Computing the terms of the normal equations\n",
    "# If sim_msr_vec is not None, it will be copied to msr_vec (and used to compute y),\n",
    "# otherwise msr_vec and y are computed from the Stokes coefficients\n",
    "N_mat, y, msr_vec = scripts.compute_normal_equations(\n",
    "    cnm_mat_est, # coefficients used to simulate measurements (if sim_msr_vec is None)\n",
    "    sph_coords, # measurements locations \n",
    "    partials_func, # function for the partials computation\n",
    "    r_0=r_0,\n",
    "    batch_size=1000, # With 1000, about 2GB RAM for n_max_est=100 and 5e4 msr\n",
    "    msr_noise=msr_noise,\n",
    "    partials_scale=partials_scale,\n",
    "    raw_msr_vec=sim_msr_vec, # synthetic measurements (if None they will be computed from cnm_mat_est)\n",
    "    perturb_msr=perturb_msr,  # contaminate synthetic measurements with Gaussian noise\n",
    "    rng=rng,\n",
    ")\n",
    "print(\"Took {:.2f} s\".format(time() - ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dd9d2",
   "metadata": {},
   "source": [
    "### Least-squares solution\n",
    "The least-squares solution for the vector of Stokes coefficients is given by\n",
    "$$\\hat{\\mathbf{x}} = (\\mathbf{H}^T\\mathbf{H})^{-1}\\mathbf{H}^T\\mathbf{z}$$\n",
    "If no covariance of the solution is required, the system of normal equations is solved via `numpy.linalg.lstsq`.\n",
    "Otherwise, we compute the singular-value decomposition of $\\mathbf{N}$, so that $\\mathbf{N} = \\mathbf{U} \\mathbf{S} \\mathbf{V^T}$, with $\\mathbf{U}$ and $\\mathbf{V}$ orthonormal matrices ($\\mathbf{V}\\mathbf{V^T} = \\mathbf{I}$), and $\\mathbf{S}$ the diagonal matrix of the singular values of $\\mathbf{N}$.\n",
    "\n",
    "The covariance of the estimated parameters will then be\n",
    "$$\\mathbf{P} = \\mathbf{V}\\mathbf{S^{-1}} \\mathbf{U^T}$$\n",
    "and the solution\n",
    "$$\\hat{\\mathbf{x}} = \\mathbf{P}\\mathbf{y}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2d8c18-e471-4485-ac0d-95fb8b44e544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving via SVD...\n",
      "Took 777.02 s\n"
     ]
    }
   ],
   "source": [
    "cnm_vec_sim = cnm_mat_sim[*cnm_idx_sim.T]  # ground-truth vector of Stokes coefficients\n",
    "\n",
    "# solution and covariance for the estimated parameters\n",
    "# if compute_covariance is False, cov will be None \n",
    "cnm_vec_est, cov = scripts.solve_normal_equations(\n",
    "    N_mat, y, compute_covariance=compute_covariance\n",
    ")\n",
    "\n",
    "if compute_covariance:\n",
    "    cnm_vec_sigma = np.sqrt(np.diagonal(cov))  # formal errors\n",
    "    corr_mat = cov / np.outer(cnm_vec_sigma, cnm_vec_sigma)  # correlations matrix\n",
    "\n",
    "# difference between estimated and ground-truth Stokes coefficients\n",
    "n_shared_coeffs = min(cnm_vec_sim.shape[0], cnm_vec_est.shape[0])\n",
    "cnm_true_errors = cnm_vec_est[:n_shared_coeffs] - cnm_vec_sim[:n_shared_coeffs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a08b0c",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d38b64-f6f1-4193-a440-ce254abd3a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"out/glq_grid/sim_msr_plot_3D.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0b4427f510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = msr_vec.reshape(-1, msr_dim)\n",
    "\n",
    "# 3D trajectory with measurement points\n",
    "fig_trj = scripts.plot_traj(state_mat, val, val_lbl=val_lbl)\n",
    "fig_out_path = os.path.join(out_path, \"sim_msr_plot_3D.html\")\n",
    "fig_trj.write_html(\n",
    "            fig_out_path,\n",
    "            include_mathjax=\"cdn\",\n",
    "            include_plotlyjs=\"cdn\",\n",
    "            config=dict({\"scrollZoom\": True}),\n",
    "        )\n",
    "IFrame(src=fig_out_path, width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca84a91-60d2-41f5-98e7-c3bd6cdea410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"out/glq_grid/sim_msr_plot_2D.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0b4494fdd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D plot of trajectory and measurements (in spherical coordinates)\n",
    "plot_coords  = sph_coords[:, [2, 1]]\n",
    "plot_coords[:,1] = np.pi/2-plot_coords[:,1]\n",
    "fig_grav_2d = scripts.plot_val_2d(\n",
    "    plot_coords/deg, val, val_lbl=val_lbl\n",
    ")\n",
    "fig_out_path = os.path.join(out_path, \"sim_msr_plot_2D.html\")\n",
    "fig_grav_2d.write_html(\n",
    "            fig_out_path,\n",
    "            include_mathjax=\"cdn\",\n",
    "            include_plotlyjs=\"cdn\",\n",
    "            config=dict({\"scrollZoom\": True}),\n",
    "        )\n",
    "IFrame(src=fig_out_path, width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350c27cf-932d-40b2-96d6-3147ec26d876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"out/glq_grid/spectrum.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0b4bb5af90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spectra of Sokes coefficients and their errors\n",
    "cnm_spectrum_sim = np.array(\n",
    "    [\n",
    "        (n, np.linalg.norm(cnm_vec_sim[cnm_idx_sim[:, 1] == n]) / np.sqrt(2 * n + 1))\n",
    "        for n in range(n_max_sim + 1)\n",
    "    ]\n",
    ")\n",
    "cnm_spectrum_est = np.array(\n",
    "    [\n",
    "        (n, np.linalg.norm(cnm_vec_est[cnm_idx_est[:, 1] == n]) / np.sqrt(2 * n + 1))\n",
    "        for n in range(n_max_est + 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Line plots of the Cnm spectra\n",
    "fig_spectrum = go.Figure()\n",
    "fig_spectrum.add_traces(\n",
    "    go.Scatter(\n",
    "        x=cnm_spectrum_sim[2:, 0],\n",
    "        y=cnm_spectrum_sim[2:, 1],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"darkgrey\", width=2),\n",
    "        showlegend=True,\n",
    "        name=\"Ground-truth\",\n",
    "    )\n",
    ")\n",
    "fig_spectrum.add_traces(\n",
    "    go.Scatter(\n",
    "        x=cnm_spectrum_est[2:, 0],\n",
    "        y=cnm_spectrum_est[2:, 1],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"royalblue\", width=2),\n",
    "        showlegend=True,\n",
    "        name=\"Estimated\",\n",
    "    )\n",
    ")\n",
    "if compute_covariance:\n",
    "    cnm_spectrum_sigma = np.array(\n",
    "        [\n",
    "            (\n",
    "                n,\n",
    "                np.linalg.norm(cnm_vec_sigma[cnm_idx_est[:, 1] == n])\n",
    "                / np.sqrt(2 * n + 1),\n",
    "            )\n",
    "            for n in range(n_max_est + 1)\n",
    "        ]\n",
    "    )\n",
    "    fig_spectrum.add_traces(\n",
    "        go.Scatter(\n",
    "            x=cnm_spectrum_sigma[2:, 0],\n",
    "            y=cnm_spectrum_sigma[2:, 1],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"royalblue\", dash=\"dash\", width=2),\n",
    "            showlegend=True,\n",
    "            name=\"Uncertainty\",\n",
    "        )\n",
    "    )\n",
    "fig_spectrum.update_layout(\n",
    "    xaxis_title=r\"$l_{\\max}$\", yaxis_title=\"Power spectrum\", yaxis_type=\"log\"\n",
    ")\n",
    "fig_out_path = os.path.join(out_path, \"spectrum.html\")\n",
    "fig_spectrum.write_html(\n",
    "            fig_out_path,\n",
    "            include_mathjax=\"cdn\",\n",
    "            include_plotlyjs=\"cdn\",\n",
    "            config=dict({\"scrollZoom\": True}),\n",
    "        )\n",
    "IFrame(src=fig_out_path, width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e238a",
   "metadata": {},
   "source": [
    "#### Error statistics\n",
    "Here we evaluate the synthetic and the estimated Stokes coefficients over a same GLQ grid, computed for degree `n_max` (maximum of `n_max_sim` and `n_max_est`) and at a radial distance of $1.1R_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e391370d-0c99-488a-bbea-f28bb90e4b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing errors on GLQ grid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 121/121 [00:34<00:00,  3.50it/s]\n",
      "100%|███████████████████████████████████| 101/101 [00:30<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 71.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing errors on GLQ grid...\")\n",
    "ts = time()\n",
    "\n",
    "# constructing matrix from vector of estimated coefficients\n",
    "cnm_mat_est = cnm_mat_est.astype(np.double)\n",
    "cnm_mat_est[*cnm_idx_est.T] = cnm_vec_est\n",
    "\n",
    "# cartesian (state_grid) and spherical(rtp_grid) coordinates of the GLQ grid points\n",
    "state_grid, rtp_grid = scripts.points_from_grid(n_max, r=(r_0 * 1.1), use_GLQ_grid=True)\n",
    "\n",
    "# forward gravity computation for ground-truth coefficients\n",
    "# The function outputs are up to a factor of gm, so we multiply them by gm\n",
    "pot_sim_grid, acc_sim_grid = [\n",
    "    el * gm for el in scripts.compute_pot_acc(cnm_mat_sim, r_0, rtp_grid)\n",
    "]\n",
    "# forward gravity computation for estimated coefficients\n",
    "pot_est_grid, acc_est_grid = [\n",
    "    el * gm for el in scripts.compute_pot_acc(cnm_mat_est, r_0, rtp_grid)\n",
    "]\n",
    "print(\"Took {:.2f} s\".format(time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48bde790-a926-4063-8e1c-64c06109d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error stats: \n",
      "Mean: -3.2795e-11 - Median: 5.3529e-12 -  RMS: 4.2685e-09 - SNR (dB):8.5645\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"out/glq_grid/true_errors_grid.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0b445c2510>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference\n",
    "err_grid = pot_sim_grid - pot_est_grid if use_potential else acc_sim_grid - acc_est_grid\n",
    "err_grid = err_grid.reshape(-1, msr_dim)\n",
    "\n",
    "rel_err = err_grid / ((pot_sim_grid if use_potential else acc_sim_grid) + 1e-20)\n",
    "\n",
    "# Mean, median, RMS, and SNR of the errors\n",
    "err_stats = [\n",
    "    np.mean(err_grid),\n",
    "    np.median(err_grid),\n",
    "    np.linalg.norm(err_grid) / np.sqrt(err_grid.size),\n",
    "]\n",
    "err_stats.append(np.log10(np.abs(np.mean(1 / (rel_err + 1e-20)))))\n",
    "print(\"Error stats: \")\n",
    "print(\"Mean: {:.5g} - Median: {:.5g} -  RMS: {:.5g} - SNR (dB):{:.5g}\".format(*err_stats))\n",
    "\n",
    "# 3D plot of the errors\n",
    "fig_diff =scripts.plot_traj(state_grid, err_grid, val_lbl=\"Error \" + val_lbl)\n",
    "fig_out_path = os.path.join(out_path, \"true_errors_grid.html\")\n",
    "fig_diff.write_html(\n",
    "        fig_out_path,\n",
    "        include_mathjax=\"cdn\",\n",
    "        include_plotlyjs=\"cdn\",\n",
    "        config=dict({\"scrollZoom\": True}),\n",
    "    )\n",
    "IFrame(src=fig_out_path, width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f339c1-4f8f-4492-a74a-783a98b2b673",
   "metadata": {},
   "source": [
    "### Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2abd56-7f23-4d7b-b786-b1f91c4c5e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500\"\n",
       "            height=\"500\"\n",
       "            src=\"out/glq_grid/true_errors_grid.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0b43a5f010>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if compute_covariance and n_max<=10:\n",
    "    # Heatmap of the correlation matrix\n",
    "    customdata = np.array(\n",
    "        [\n",
    "            \"{}_{:d},{:d} - {}_{:d},{:d}\".format(\n",
    "                \"C\" if el_1[0] == 0 else \"S\",\n",
    "                el_1[1],\n",
    "                el_1[2],\n",
    "                \"C\" if el_2[0] == 0 else \"S\",\n",
    "                el_2[1],\n",
    "                el_2[2],\n",
    "            )\n",
    "            for el_1 in cnm_idx_est\n",
    "            for el_2 in cnm_idx_est\n",
    "        ]\n",
    "    )\n",
    "    fig_corr = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=corr_mat,\n",
    "            customdata=customdata.reshape(corr_mat.shape),\n",
    "            hovertemplate=\"<b>%{customdata}</b><br>%{z:.3f}\",\n",
    "            colorscale=\"RdBu_r\",\n",
    "        )\n",
    "    )\n",
    "    fig_out_path = os.path.join(out_path, \"correlations.html\")\n",
    "    fig_corr.write_html(\n",
    "            fig_out_path,\n",
    "            include_mathjax=\"cdn\",\n",
    "            include_plotlyjs=\"cdn\",\n",
    "            config=dict({\"scrollZoom\": True}),\n",
    "        )\n",
    "    IFrame(src=fig_out_path, width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19488eae-0574-48fe-ac85-fd4257e835eb",
   "metadata": {},
   "source": [
    "### Storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0eb67d-df73-4838-a44a-47c6d6c802c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Stokes coefficients in the SHADR format. Can be read via scripts.read_shadr or in SHTOOLS via sh.SHGravCoeffs.from_file\n",
    "cnm_gt_file = \"cnm_ground_truth\"\n",
    "scripts.write_SHADR(\n",
    "    os.path.join(out_path, cnm_gt_file + \".txt\"),\n",
    "    cnm_vec_sim,\n",
    "    cnm_map_sim,\n",
    "    gm=gm,\n",
    "    r_0=r_0,\n",
    ")\n",
    "\n",
    "cnm_sol_file = \"cnm_estimated\"\n",
    "scripts.write_SHADR(\n",
    "    os.path.join(out_path, cnm_sol_file + \".txt\"),\n",
    "    cnm_vec_est,\n",
    "    cnm_map_est,\n",
    "    gm=gm,\n",
    "    r_0=r_0,\n",
    ")\n",
    "\n",
    "# Saving measurements evaluated on a spherical grid\n",
    "grid_gt_file = \"grid_ground_truth\"\n",
    "scripts.save_msr_grid(\n",
    "    os.path.join(out_path, grid_gt_file + \".pkl\"),\n",
    "    rtp_grid,\n",
    "    pot_sim_grid if use_potential else acc_sim_grid,\n",
    ")\n",
    "grid_est_file = \"grid_estimated\"\n",
    "scripts.save_msr_grid(\n",
    "    os.path.join(out_path, grid_est_file + \".pkl\"),\n",
    "    rtp_grid,\n",
    "    pot_est_grid if use_potential else acc_est_grid,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
